{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "from utils import *\n",
    "from training import *\n",
    "from models import *\n",
    "\n",
    "model = EncoderDecoder(34,10,256)\n",
    "model.load_state_dict(torch.load(\"maml_yonc_256_5.weights\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lst):\n",
    "    new_list = []\n",
    "    for elt in lst:\n",
    "        new_list = new_list + elt\n",
    "        \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringify_lst(lst):\n",
    "    joined = \", \".join([str(x) for x in lst])\n",
    "    return \"[\" + joined + \"]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *\n",
    "from utils import *\n",
    "from training import *\n",
    "from models import *\n",
    "\n",
    "model = EncoderDecoder(34,10,256, recurrent_unit=\"GRU\")\n",
    "model.load_state_dict(torch.load(\"yonc_maml_gru_256_5.weights\"))\n",
    "model.set_dicts(\"a e i o u A E I O U b c d f g h j k l m n p q r s t v w x z .\".split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tommccoy/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[[-3.1345e+01, -3.1722e+01, -1.0695e+01, -1.1993e+01, -1.9148e+01,\n",
       "           -1.8033e+01, -1.8337e+01, -2.0455e+01, -1.7708e+01, -1.9106e+01,\n",
       "           -1.7292e+01, -2.0588e+01, -2.1188e+01, -2.1301e+01, -1.7761e+01,\n",
       "           -1.7994e+01, -2.0617e+01, -2.2182e+01, -2.0595e+01, -1.8950e+01,\n",
       "           -2.4255e+01, -2.0938e+01, -1.6749e+01, -2.1373e+01, -1.9037e+01,\n",
       "           -1.9733e+01, -2.0761e+01, -1.6086e+01, -1.9191e+01, -1.6779e+01,\n",
       "           -2.0447e+01, -2.0326e+01, -8.7156e+00, -1.9322e-04]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-2.5725e+01, -2.5668e+01, -1.1383e+01, -9.6359e+00, -1.6666e+01,\n",
       "           -1.5934e+01, -1.6515e+01, -1.7916e+01, -1.5906e+01, -1.6670e+01,\n",
       "           -1.5977e+01, -1.8716e+01, -1.9436e+01, -1.3169e+01, -9.7857e+00,\n",
       "           -9.6532e+00, -1.2284e+01, -1.4586e+01, -1.2750e+01, -1.0180e+01,\n",
       "           -1.6266e+01, -1.3031e+01, -9.9095e+00, -1.2121e+01, -1.0848e+01,\n",
       "           -1.1269e+01, -1.2470e+01, -7.2635e+00, -1.1487e+01, -8.2810e+00,\n",
       "           -1.1844e+01, -1.3061e+01, -1.3135e-03, -1.5480e+01]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-2.7539e+01, -2.7359e+01, -1.3171e+01, -1.2450e-03, -1.0007e+01,\n",
       "           -7.3815e+00, -1.1806e+01, -1.0662e+01, -7.9450e+00, -1.0501e+01,\n",
       "           -8.7805e+00, -1.2097e+01, -1.4013e+01, -2.1597e+01, -1.8079e+01,\n",
       "           -1.9968e+01, -1.7478e+01, -2.0429e+01, -1.7876e+01, -1.7750e+01,\n",
       "           -2.0317e+01, -1.9816e+01, -1.9489e+01, -2.0251e+01, -1.9857e+01,\n",
       "           -2.2711e+01, -2.1191e+01, -1.8970e+01, -1.9247e+01, -1.7932e+01,\n",
       "           -1.9929e+01, -2.0714e+01, -1.4020e+01, -1.4188e+01]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-3.6930e+01, -3.7169e+01, -1.1793e+01, -1.2579e+01, -1.9547e+01,\n",
       "           -1.7417e+01, -1.9473e+01, -1.7523e+01, -1.6554e+01, -1.8687e+01,\n",
       "           -1.9719e+01, -1.8384e+01, -2.1955e+01, -2.1350e+01, -1.8604e+01,\n",
       "           -2.0297e+01, -1.7707e+01, -1.9250e+01, -1.6592e+01, -1.7618e+01,\n",
       "           -2.1312e+01, -1.8926e+01, -1.8808e+01, -2.1165e+01, -2.0917e+01,\n",
       "           -1.9879e+01, -2.1552e+01, -1.9716e+01, -1.8407e+01, -1.8395e+01,\n",
       "           -1.9266e+01, -1.9455e+01, -1.4802e+01, -1.1563e-05]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-3.5782e+01, -3.5732e+01, -1.2994e-05, -1.1853e+01, -1.8670e+01,\n",
       "           -1.6327e+01, -1.8053e+01, -1.6042e+01, -1.5185e+01, -1.8454e+01,\n",
       "           -1.8694e+01, -1.7307e+01, -2.1504e+01, -1.9561e+01, -1.8438e+01,\n",
       "           -1.9011e+01, -1.7082e+01, -1.6859e+01, -1.4549e+01, -1.6109e+01,\n",
       "           -1.9427e+01, -1.8110e+01, -1.6620e+01, -1.8749e+01, -1.8155e+01,\n",
       "           -1.8270e+01, -2.0249e+01, -1.7553e+01, -1.5800e+01, -1.6875e+01,\n",
       "           -1.6410e+01, -1.7252e+01, -1.2786e+01, -1.3331e+01]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-24.3661, -23.9930,  -1.4579,  -0.6249,  -4.1032,  -5.0865,  -5.8230,\n",
       "            -3.0418,  -2.8759,  -3.6333,  -3.9914,  -3.7754,  -7.4964, -16.3347,\n",
       "           -15.8858, -16.4654, -13.8869, -12.7507, -11.3317, -12.0589, -16.2618,\n",
       "           -11.1733, -12.5542, -15.8165, -16.8890, -16.9239, -19.3127, -14.0017,\n",
       "            -9.7758, -12.8463, -12.4979, -11.3867, -12.0453,  -3.3905]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-3.4134e+01, -3.3882e+01, -8.2424e+00, -1.4594e+01, -1.7959e+01,\n",
       "           -1.6240e+01, -1.5598e+01, -1.3560e+01, -1.5279e+01, -1.5501e+01,\n",
       "           -1.6300e+01, -1.6242e+01, -1.8020e+01, -1.9077e+01, -1.8157e+01,\n",
       "           -2.0395e+01, -1.4706e+01, -1.5307e+01, -1.7804e+01, -1.8199e+01,\n",
       "           -1.9154e+01, -1.3984e+01, -1.6321e+01, -1.8892e+01, -2.1487e+01,\n",
       "           -1.9721e+01, -2.0400e+01, -1.8125e+01, -1.5668e+01, -1.6707e+01,\n",
       "           -1.5201e+01, -1.7834e+01, -1.6558e+01, -2.6807e-04]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-4.0146e+01, -3.9918e+01, -3.2186e-06, -1.8445e+01, -2.1928e+01,\n",
       "           -1.9258e+01, -1.7150e+01, -1.5325e+01, -1.9926e+01, -1.8770e+01,\n",
       "           -1.9762e+01, -1.9232e+01, -2.1285e+01, -2.0067e+01, -1.9772e+01,\n",
       "           -2.1334e+01, -1.5898e+01, -1.4581e+01, -1.8309e+01, -1.9338e+01,\n",
       "           -1.8896e+01, -1.5356e+01, -1.6927e+01, -1.9273e+01, -2.0917e+01,\n",
       "           -2.0229e+01, -2.0418e+01, -1.9207e+01, -1.6783e+01, -1.6870e+01,\n",
       "           -1.6603e+01, -1.8403e+01, -1.6014e+01, -1.3195e+01]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-25.7588, -25.3770,  -3.2394,  -4.5511,  -5.8946,  -5.8282,  -2.6741,\n",
       "            -0.2792,  -4.3331,  -2.6797,  -4.6914,  -3.8995,  -5.4631, -14.8063,\n",
       "           -17.9804, -16.1081, -13.6498, -12.5189, -12.8905, -12.9881, -15.4813,\n",
       "           -11.5525, -13.7918, -14.4346, -17.8851, -16.2256, -17.6373, -14.1918,\n",
       "           -13.2143, -12.8291, -11.8239, -11.7625, -14.2304,  -5.5825]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-3.5698e+01, -3.5472e+01, -1.0887e+01, -1.6516e+01, -1.9780e+01,\n",
       "           -1.7074e+01, -1.5452e+01, -1.3535e+01, -1.6344e+01, -1.6324e+01,\n",
       "           -1.6663e+01, -1.6968e+01, -1.8488e+01, -1.8574e+01, -2.1287e+01,\n",
       "           -2.1598e+01, -1.6370e+01, -1.6351e+01, -1.9060e+01, -1.9894e+01,\n",
       "           -2.0394e+01, -1.4764e+01, -1.8128e+01, -1.9520e+01, -2.3130e+01,\n",
       "           -2.0149e+01, -2.1135e+01, -2.0451e+01, -1.8564e+01, -1.7994e+01,\n",
       "           -1.5257e+01, -1.8511e+01, -2.0355e+01, -2.1338e-05]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-3.9022e+01, -3.8811e+01, -1.7166e-05, -1.7837e+01, -2.1481e+01,\n",
       "           -1.8242e+01, -1.6001e+01, -1.4412e+01, -1.8680e+01, -1.7512e+01,\n",
       "           -1.8894e+01, -1.7728e+01, -2.0759e+01, -1.9036e+01, -1.9900e+01,\n",
       "           -2.1008e+01, -1.6600e+01, -1.4524e+01, -1.7888e+01, -1.9668e+01,\n",
       "           -1.8503e+01, -1.5610e+01, -1.7166e+01, -1.8443e+01, -2.0223e+01,\n",
       "           -1.9897e+01, -1.9869e+01, -1.9502e+01, -1.6960e+01, -1.7418e+01,\n",
       "           -1.5942e+01, -1.7195e+01, -1.7200e+01, -1.1079e+01]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-24.3236, -24.1299,  -1.7928,  -5.2477,  -6.6392,  -5.4703,  -2.9471,\n",
       "            -0.4436,  -4.9014,  -2.9353,  -4.3820,  -3.4449,  -5.8112, -13.0575,\n",
       "           -15.0847, -14.7030, -12.1746, -10.0769, -10.6523, -11.4951, -13.4235,\n",
       "            -9.4721, -11.5878, -13.4197, -14.7009, -14.5753, -15.3534, -12.7920,\n",
       "           -10.8379, -11.8817, -10.8086, -10.2622, -12.6873,  -3.8967]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-3.6323e+01, -3.6131e+01, -9.8250e+00, -1.8067e+01, -2.1717e+01,\n",
       "           -1.8143e+01, -1.6682e+01, -1.4902e+01, -1.8018e+01, -1.7114e+01,\n",
       "           -1.7264e+01, -1.7906e+01, -2.0010e+01, -1.9181e+01, -2.0327e+01,\n",
       "           -2.2275e+01, -1.7018e+01, -1.6091e+01, -1.9427e+01, -2.0532e+01,\n",
       "           -2.0530e+01, -1.4432e+01, -1.7964e+01, -2.0908e+01, -2.2692e+01,\n",
       "           -2.0746e+01, -2.1376e+01, -2.0804e+01, -1.8005e+01, -1.8861e+01,\n",
       "           -1.6846e+01, -1.8981e+01, -2.0605e+01, -5.5312e-05]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-3.8055e+01, -3.7892e+01, -1.4424e-05, -1.8481e+01, -2.2188e+01,\n",
       "           -1.8687e+01, -1.6514e+01, -1.5038e+01, -1.9043e+01, -1.7957e+01,\n",
       "           -1.8596e+01, -1.8275e+01, -2.1488e+01, -1.9476e+01, -1.9056e+01,\n",
       "           -2.1363e+01, -1.6532e+01, -1.3914e+01, -1.7929e+01, -1.9797e+01,\n",
       "           -1.8293e+01, -1.4961e+01, -1.6697e+01, -1.9311e+01, -1.9484e+01,\n",
       "           -2.0236e+01, -1.9681e+01, -1.9491e+01, -1.6795e+01, -1.7889e+01,\n",
       "           -1.6632e+01, -1.7314e+01, -1.7301e+01, -1.1302e+01]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-24.1390, -23.8396,  -1.6549,  -5.2734,  -6.5983,  -5.5330,  -2.7816,\n",
       "            -0.5531,  -4.5634,  -2.5817,  -3.5425,  -3.3009,  -6.1358, -13.5785,\n",
       "           -14.9882, -14.9893, -12.9701, -10.2612, -10.8443, -11.9153, -13.9145,\n",
       "            -9.7761, -11.7856, -14.0405, -14.3617, -15.3076, -15.6700, -13.1910,\n",
       "           -10.9935, -12.8214, -11.5995, -10.2976, -13.0771,  -4.9437]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-3.5821e+01, -3.5660e+01, -1.0381e+01, -1.8229e+01, -2.1758e+01,\n",
       "           -1.8498e+01, -1.6885e+01, -1.4704e+01, -1.7950e+01, -1.6914e+01,\n",
       "           -1.7195e+01, -1.8053e+01, -2.0336e+01, -1.9508e+01, -2.0482e+01,\n",
       "           -2.2491e+01, -1.7675e+01, -1.6095e+01, -1.9494e+01, -2.0731e+01,\n",
       "           -2.0808e+01, -1.4692e+01, -1.8248e+01, -2.1067e+01, -2.2743e+01,\n",
       "           -2.0842e+01, -2.1622e+01, -2.0976e+01, -1.7932e+01, -1.9565e+01,\n",
       "           -1.6930e+01, -1.8912e+01, -2.1359e+01, -3.2305e-05]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-3.7278e+01, -3.7117e+01, -2.5868e-05, -1.8051e+01, -2.1908e+01,\n",
       "           -1.8271e+01, -1.6138e+01, -1.4583e+01, -1.8471e+01, -1.7386e+01,\n",
       "           -1.8214e+01, -1.7997e+01, -2.1271e+01, -1.9537e+01, -1.8960e+01,\n",
       "           -2.1307e+01, -1.6971e+01, -1.3898e+01, -1.7988e+01, -1.9767e+01,\n",
       "           -1.8341e+01, -1.5111e+01, -1.6618e+01, -1.9212e+01, -1.9236e+01,\n",
       "           -2.0067e+01, -1.9638e+01, -1.9325e+01, -1.6625e+01, -1.8208e+01,\n",
       "           -1.6662e+01, -1.7005e+01, -1.7555e+01, -1.0653e+01]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-23.5209, -23.2520,  -1.5674,  -5.1891,  -6.8530,  -5.6592,  -3.2306,\n",
       "            -0.4923,  -4.3097,  -2.7764,  -3.6843,  -3.8025,  -6.7673, -12.6473,\n",
       "           -14.2376, -14.2896, -12.4408,  -9.3699, -10.2297, -11.1932, -13.1407,\n",
       "            -8.9915, -11.1478, -13.1992, -13.4301, -14.1808, -14.6562, -12.6317,\n",
       "           -10.2993, -12.3520, -10.9276,  -9.5356, -12.5300,  -5.1485]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-3.4864e+01, -3.4771e+01, -1.0556e+01, -1.8161e+01, -2.1678e+01,\n",
       "           -1.8273e+01, -1.6870e+01, -1.4366e+01, -1.7939e+01, -1.6986e+01,\n",
       "           -1.7126e+01, -1.7959e+01, -2.0305e+01, -1.8896e+01, -2.0030e+01,\n",
       "           -2.2323e+01, -1.7252e+01, -1.5459e+01, -1.9141e+01, -1.9893e+01,\n",
       "           -2.0317e+01, -1.3857e+01, -1.8134e+01, -2.0652e+01, -2.2451e+01,\n",
       "           -2.0064e+01, -2.1091e+01, -2.0927e+01, -1.7766e+01, -1.9104e+01,\n",
       "           -1.6429e+01, -1.8720e+01, -2.1409e+01, -2.8014e-05]]],\n",
       "        grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-3.6011e+01, -3.5885e+01, -3.8861e-05, -1.7606e+01, -2.1458e+01,\n",
       "           -1.7576e+01, -1.5684e+01, -1.3984e+01, -1.7938e+01, -1.7088e+01,\n",
       "           -1.7856e+01, -1.7453e+01, -2.0782e+01, -1.9134e+01, -1.8564e+01,\n",
       "           -2.1171e+01, -1.6642e+01, -1.3368e+01, -1.7662e+01, -1.9068e+01,\n",
       "           -1.7863e+01, -1.4555e+01, -1.6515e+01, -1.8917e+01, -1.8916e+01,\n",
       "           -1.9525e+01, -1.9183e+01, -1.9216e+01, -1.6646e+01, -1.7895e+01,\n",
       "           -1.6372e+01, -1.6811e+01, -1.7588e+01, -1.0254e+01]]],\n",
       "        grad_fn=<LogSoftmaxBackward>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model([\"za\"])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retry\n",
    "uz = model.enc_lstm.wz_weights.transpose(0,1)[:10].data.numpy().transpose() # GOOD\n",
    "wz = model.enc_lstm.wz_weights.transpose(0,1)[10:].data.numpy().transpose()\n",
    "bz = model.enc_lstm.wz_bias.data.numpy() # GOOD\n",
    "\n",
    "ur = model.enc_lstm.wr_weights.transpose(0,1)[:10].data.numpy().transpose()\n",
    "wr = model.enc_lstm.wr_weights.transpose(0,1)[10:].data.numpy().transpose()\n",
    "br = model.enc_lstm.wr_bias.data.numpy()\n",
    "\n",
    "ux = model.enc_lstm.wx_weights.transpose(0,1).data.numpy().transpose() # GOOD\n",
    "wx = model.enc_lstm.wrh_weights.transpose(0,1).data.numpy().transpose()\n",
    "bx = model.enc_lstm.wx_bias.data.numpy() + model.enc_lstm.wrh_bias.data.numpy() # GOOD\n",
    "\n",
    "\n",
    "full_w = flatten(np.concatenate([wz.transpose(), wr.transpose(), wx.transpose()], axis=1).tolist())\n",
    "full_x = flatten(np.concatenate([uz, ur, ux], axis=0).transpose().tolist()) # CORRECT\n",
    "full_b = flatten(np.concatenate([np.expand_dims(bz,1),np.expand_dims(br,1),np.expand_dims(bx,1)], axis=0).tolist()) # CORRECT\n",
    "\n",
    "# No internal transpose:\n",
    "# 0, no transpose: wrong\n",
    "# 1, no transpose: right first thing, but not rest\n",
    "# 0, transpose: wrong\n",
    "# 1, transpose: wrong\n",
    "\n",
    "# Internal transpose:\n",
    "# 0, no transpose: wrong\n",
    "# 1, no transpose: wrong\n",
    "# 0, transpose: right first thing, but not rest\n",
    "# 1, transpose: wrong\n",
    "\n",
    "\n",
    "# Retry\n",
    "uzd = model.dec_lstm.wz_weights.transpose(0,1)[:10].data.numpy().transpose() # GOOD\n",
    "wzd = model.dec_lstm.wz_weights.transpose(0,1)[10:].data.numpy().transpose()\n",
    "bzd = model.dec_lstm.wz_bias.data.numpy() # GOOD\n",
    "\n",
    "urd = model.dec_lstm.wr_weights.transpose(0,1)[:10].data.numpy().transpose()\n",
    "wrd = model.dec_lstm.wr_weights.transpose(0,1)[10:].data.numpy().transpose()\n",
    "brd = model.dec_lstm.wr_bias.data.numpy()\n",
    "\n",
    "uxd = model.dec_lstm.wx_weights.transpose(0,1).data.numpy().transpose() # GOOD\n",
    "wxd = model.dec_lstm.wrh_weights.transpose(0,1).data.numpy().transpose()\n",
    "bxd = model.dec_lstm.wx_bias.data.numpy() + model.dec_lstm.wrh_bias.data.numpy() # GOOD\n",
    "\n",
    "\n",
    "full_wd = flatten(np.concatenate([wzd.transpose(), wrd.transpose(), wxd.transpose()], axis=1).tolist())\n",
    "full_xd = flatten(np.concatenate([uzd, urd, uxd], axis=0).transpose().tolist()) # CORRECT\n",
    "full_bd = flatten(np.concatenate([np.expand_dims(bzd,1),np.expand_dims(brd,1),np.expand_dims(bxd,1)], axis=0).tolist()) # CORRECT\n",
    "\n",
    "\n",
    "\n",
    "tf_weights = open(\"tf_weights.js\", \"w\")\n",
    "tf_weights.write(\"emb_wg = \" + stringify_lst(flatten(model.embedding.weights.data.numpy().tolist())) + \";\\n\")\n",
    "tf_weights.write(\"full_x = \" + stringify_lst(full_x) + \";\\n\")\n",
    "tf_weights.write(\"full_w = \" + stringify_lst(full_w) + \";\\n\")\n",
    "tf_weights.write(\"full_b = \" + stringify_lst(full_b) + \";\\n\")\n",
    "tf_weights.write(\"full_xd = \" + stringify_lst(full_xd) + \";\\n\")\n",
    "tf_weights.write(\"full_wd = \" + stringify_lst(full_wd) + \";\\n\")\n",
    "tf_weights.write(\"full_bd = \" + stringify_lst(full_bd) + \";\\n\")\n",
    "tf_weights.write(\"out_wg = \" + stringify_lst(flatten(model.dec_output.weights.transpose(0,1).data.numpy().tolist())) + \";\\n\")\n",
    "tf_weights.write(\"out_wb = \" + stringify_lst(model.dec_output.bias.data.numpy().tolist()) + \";\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
