---
permalink: /pubs/
author_profile: true
redirect_from:
  - /pubs
---

{% include base_path %}


# In progress

<p style="margin-left: 40px; text-indent: -40px;">
<b>R. Thomas McCoy</b>, Ellie Pavlick, and Tal Linzen. Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference.
</p>

<p style="margin-left: 40px; text-indent: -40px;">
Samuel R. Bowman, Ellie Pavlick, Edouard Grave, Benjamin Van Durme, Alex Wang, Jan Hula, Patrick Xia, Raghavendra Pappagari, <b>R. Thomas McCoy</b>, Roma Patel, Najoung Kim, Ian Tenney, Yinghui Huang, Katherin Yu, Shuning Jin, and Berline Chen. Looking for ELMo's Friends: Sentence-Level Pretraining Beyond Language Modeling.
</p>

# 2019

<p style="margin-left: 40px; text-indent: -40px;">
Najoung Kim, Roma Patel, Adam Poliak, Alex Wang, Patrick Xia, <b>R. Thomas McCoy</b>, Ian Tenney, Alexis Ross, Tal Linzen, Benjamin Van Durme, Samuel R. Bowman, and Ellie Pavlick. Probing What Different NLP Tasks Teach Machines about Function Word Comprehension. To appear in <em>Proceedings of the Eight Joint Conference on Lexical and Computational Semantics (\&ast;SEM 2019)</em>.
</p>

<p style="margin-left: 40px; text-indent: -40px;">
<b>R. Thomas McCoy</b>, Tal Linzen, Ewan Dunbar, and Paul Smolensky. RNNs implicitly implement tensor-product representations. In <em>International Conference on Learning Representations 2019</em>. 
</p>

<p style="margin-left: 40px; text-indent: -40px;">
Ian Tenney, Patrick Xia, Berline Chen, Alex Wang, Adam Poliak, <b>R. Thomas McCoy</b>, Najoung Kim, Benjamin Van Durme, Samuel R. Bowman, Dipanjan Das, and Ellie Pavlick. What do you learn from context? Probing for sentence structure in contextualized word representations. In <em>International Conference on Learning Representations 2019</em>.
</p>

<p style="margin-left: 40px; text-indent: -40px;">
<b>R. Thomas McCoy</b> and Tal Linzen. Non-entailed subsequences as a challenge for natural language inference. In <em>Proceedings of the Society for Computation in Linguistics (SCiL) 2019</em>.
</p>

# 2018

<p style="margin-left: 40px; text-indent: -40px;">
<b>R. Thomas McCoy</b>, Robert Frank, and Tal Linzen. 2018. Revisiting the poverty of
the stimulus: hierarchical generalization without a hierarchical bias in recurrent
neural networks. To appear in <em>Proceedings of the 40th Annual Conference of the
Cognitive Science Society</em>.
</p>

<p style="margin-left: 40px; text-indent: -40px;">
Patrick Littell, <b>R. Thomas McCoy</b>, Na-Rae Han, Shruti Rijhwani, Zaid Sheikh,
David Mortensen, Teruko Mitamura, and Lori Levin. 2018. Parser combinators for
Tigrinya and Oromo morphology. To appear in <em>Language Resources and Evaluation
Conference (LREC) 2018</em>.
</p>

<p style="margin-left: 40px; text-indent: -40px;">
<b>R. Thomas McCoy</b> and Robert Frank. 2018. Phonologically Informed Edit Distance
Algorithms for Word Alignment with Low-Resource Languages. In <em>Proceedings
of the Society for Computation in Linguistics (SCiL) 2018</em>, pages 102-112.
</p>

# 2017

<p style="margin-left: 40px; text-indent: -40px;">
Jungo Kasai, Bob Frank, <b>R. Thomas McCoy</b>, Owen Rambow, and Alexis Nasr. 2017.
Tag parsing with neural networks and vector representations of supertags. In
<em>Proceedings of the 2017 Conference on Empirical Methods in Natural Language
Processing</em>, pages 1712-1722.
</p>

<p style="margin-left: 40px; text-indent: -40px;">
Dan Friedman&ast;, Jungo Kasai&ast;, <b>R. Thomas McCoy</b>&ast;, Robert Frank, Forrest Davis,
Owen Rambow. Linguistically Rich Vector Representations of Supertags for TAG
Parsing. In <em>Proceedings of the 13th International Workshop on Tree Adjoining
Grammars and Related Formalisms</em>, pages 122-131.  
&ast;Equal contribution.
</p>

<p style="margin-left: 40px; text-indent: -40px;">
<b>R. Thomas McCoy</b>. 2017. English comparatives as degree-phrase relative clauses. In
<em>Proceedings of the Linguistic Society of America 2</em>, 26:1-7.
</p>
