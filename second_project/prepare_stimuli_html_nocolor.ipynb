{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of items\n",
    "\n",
    "# Number of training items for each n\n",
    "# L&P did 144: 48 for n=1, 48 for n=2, 48 for n=3\n",
    "count_train_1 = 16 \n",
    "count_train_2 = 16 \n",
    "count_train_3 = 16\n",
    "\n",
    "count_test_seen = 10\n",
    "count_test_good = 10\n",
    "count_test_nm = 5\n",
    "count_test_nodep = 5\n",
    "count_test_long = 5\n",
    "count_test_longone = 5\n",
    "count_test_long_nodep = 5\n",
    "count_test_atob = 5\n",
    "\n",
    "\n",
    "# Whether to allow sequences to repeat within the training set\n",
    "# Note: Have to allow repeats for n = 1\n",
    "sequence_repeats = False\n",
    "\n",
    "# Whether to allow syllables to repeat within a particular training item\n",
    "syll_repeats = False\n",
    "\n",
    "# Whether we are starting small - i.e., whether the training set should be arranged by size\n",
    "starting_small = False\n",
    "\n",
    "# Whether the buttons are arranged in order or not\n",
    "buttons_ordered = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_in_list(lst, item):\n",
    "    count = 0\n",
    "    for elt in lst:\n",
    "        if elt == item:\n",
    "            count += 1\n",
    "            \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "syll_dict = {}\n",
    "syll_dict[\"b\"] = [\"be\", \"bi\"]\n",
    "syll_dict[\"d\"] = [\"de\", \"di\"]\n",
    "syll_dict[\"g\"] = [\"ge\", \"gi\"]\n",
    "syll_dict[\"p\"] = [\"po\", \"pu\"]\n",
    "syll_dict[\"t\"] = [\"to\", \"tu\"]\n",
    "syll_dict[\"k\"] = [\"ko\", \"ku\"]\n",
    "\n",
    "ones = [[\"b\", \"p\"], [\"d\", \"t\"], [\"g\", \"k\"]]\n",
    "\n",
    "def gen_good(half_length):\n",
    "    full_onsets = []\n",
    "    \n",
    "    for i in range(half_length):\n",
    "        if syll_repeats:\n",
    "            new_pair = random.choice(ones)\n",
    "            full_onsets = [new_pair[0]] + full_onsets + [new_pair[1]]\n",
    "        else:\n",
    "            satisfied = False\n",
    "            while not satisfied:\n",
    "                candidate_pair = random.choice(ones)\n",
    "                if count_in_list(full_onsets, candidate_pair[0]) < 2:\n",
    "                    satisfied = True\n",
    "                    full_onsets = [candidate_pair[0]] + full_onsets + [candidate_pair[1]]\n",
    "                \n",
    "    words = []\n",
    "    for onset in full_onsets:\n",
    "        if syll_repeats:\n",
    "            words.append(random.choice(syll_dict[onset]))\n",
    "        else:\n",
    "            satisfied = False\n",
    "            while not satisfied:\n",
    "                candidate_syll = random.choice(syll_dict[onset])\n",
    "                if candidate_syll not in words:\n",
    "                    words.append(candidate_syll)\n",
    "                    satisfied = True\n",
    "            \n",
    "    return words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_set(count_1, count_2, count_3, count_4, list_to_avoid, no_repeats_period=False):\n",
    "    training_set = []\n",
    "    training_dict = {}\n",
    "    for elt in list_to_avoid:\n",
    "        training_dict[tuple(elt)] = 1\n",
    "    \n",
    "    for i in range(count_1):\n",
    "        train_item = gen_good(1)\n",
    "        \n",
    "        if not sequence_repeats:\n",
    "            satisfied = False\n",
    "            while not satisfied:\n",
    "                train_item = gen_good(1)\n",
    "                if tuple(train_item) not in training_dict:\n",
    "                    satisfied = True\n",
    "        \n",
    "        training_set.append(train_item)\n",
    "        \n",
    "        if no_repeats_period:\n",
    "            training_dict[tuple(train_item)] = 1\n",
    "        \n",
    "    for i in range(count_2):\n",
    "        train_item = gen_good(2)\n",
    "        \n",
    "        if not sequence_repeats:\n",
    "            satisfied = False\n",
    "            while not satisfied:\n",
    "                train_item = gen_good(2)\n",
    "                if tuple(train_item) not in training_dict:\n",
    "                    satisfied = True\n",
    "        \n",
    "        training_set.append(train_item)\n",
    "        training_dict[tuple(train_item)] = 1\n",
    "        \n",
    "    for i in range(count_3):\n",
    "        train_item = gen_good(3)\n",
    "        \n",
    "        if not sequence_repeats:\n",
    "            satisfied = False\n",
    "            while not satisfied:\n",
    "                train_item = gen_good(3)\n",
    "                if tuple(train_item) not in training_dict:\n",
    "                    satisfied = True\n",
    "        \n",
    "        training_set.append(train_item)\n",
    "        training_dict[tuple(train_item)] = 1\n",
    "        \n",
    "    for i in range(count_4):\n",
    "        train_item = gen_good(4)\n",
    "        \n",
    "        if not sequence_repeats:\n",
    "            satisfied = False\n",
    "            while not satisfied:\n",
    "                train_item = gen_good(4)\n",
    "                if tuple(train_item) not in training_dict:\n",
    "                    satisfied = True\n",
    "        \n",
    "        training_set.append(train_item)\n",
    "        training_dict[tuple(train_item)] = 1\n",
    "        \n",
    "    if not starting_small:\n",
    "        shuffle(training_set)\n",
    "        \n",
    "    return training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_summing_to(overall_count):\n",
    "    count_1 = random.randint(0,overall_count)\n",
    "    count_2 = random.randint(0,overall_count - count_1)\n",
    "    count_3 = overall_count - count_1 - count_2\n",
    "    \n",
    "    return count_1, count_2, count_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_good(overall_count):\n",
    "    count_1, count_2, count_3 = triple_summing_to(overall_count)\n",
    "    \n",
    "    return generate_training_set(count_1, count_2, count_3, 0, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "starters = [\"be\", \"bi\", \"de\", \"di\", \"ge\", \"gi\"]\n",
    "enders = [\"po\", \"pu\", \"to\", \"tu\", \"ko\", \"ku\"]\n",
    "\n",
    "def generate_nm_short(overall_count):\n",
    "    count_2 = random.randint(0,overall_count)\n",
    "    count_3 = overall_count - count_2\n",
    "    \n",
    "    to_modify = generate_training_set(0, count_2, count_3, 0, [])\n",
    "    \n",
    "    to_return = []\n",
    "    \n",
    "    for elt in to_modify:\n",
    "        starting = random.choice([True, False])\n",
    "        if starting:\n",
    "            to_return.append(elt[:-1])\n",
    "        else:\n",
    "            to_return.append(elt[1:])\n",
    "            \n",
    "    return to_return\n",
    "\n",
    "def generate_nm_long(overall_count):\n",
    "    count_4 = overall_count\n",
    "    \n",
    "    to_modify = generate_training_set(0, 0, 0, count_4, [])\n",
    "    \n",
    "    to_return = []\n",
    "    \n",
    "    for elt in to_modify:\n",
    "        starting = random.choice([True, False])\n",
    "        if starting:\n",
    "            to_return.append(elt[:-1])\n",
    "        else:\n",
    "            to_return.append(elt[1:])\n",
    "            \n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_nodep_short(overall_count):\n",
    "    count_1, count_2, count_3 = triple_summing_to(overall_count)\n",
    "    \n",
    "    to_modify = generate_training_set(count_1, count_2, count_3, 0, [])\n",
    "    \n",
    "    to_return = []\n",
    "    \n",
    "    for elt in to_modify:\n",
    "        if len(elt) == 2 or len(elt) == 4:\n",
    "            position = 0\n",
    "        elif len(elt) == 6:\n",
    "            position = random.choice([0,1])\n",
    "        else:\n",
    "            print(\"BAD LENGTH\")\n",
    "            \n",
    "        to_replace = elt[position]\n",
    "        \n",
    "        if to_replace[0] == \"b\":\n",
    "            new_start = random.choice([\"d\", \"g\"])\n",
    "        elif to_replace[0] == \"d\":\n",
    "            new_start = random.choice([\"b\", \"g\"])\n",
    "        elif to_replace[0] == \"g\":\n",
    "            new_start = random.choice([\"b\", \"d\"])\n",
    "        else:\n",
    "            print(\"BAD ONSET\")\n",
    "            \n",
    "        new_syll = random.choice(syll_dict[new_start])\n",
    "        elt[position] = new_syll\n",
    "        \n",
    "        to_return.append(elt)\n",
    "            \n",
    "            \n",
    "    return to_return\n",
    "\n",
    "def generate_nodep_long(overall_count):\n",
    "    count_4 = overall_count\n",
    "    \n",
    "    to_modify = generate_training_set(0, 0, 0, count_4, [])\n",
    "    \n",
    "    to_return = []\n",
    "    \n",
    "    for elt in to_modify:\n",
    "        position = random.choice([0,1,2])\n",
    "            \n",
    "        to_replace = elt[position]\n",
    "        \n",
    "        if to_replace[0] == \"b\":\n",
    "            new_start = random.choice([\"d\", \"g\"])\n",
    "        elif to_replace[0] == \"d\":\n",
    "            new_start = random.choice([\"b\", \"g\"])\n",
    "        elif to_replace[0] == \"g\":\n",
    "            new_start = random.choice([\"b\", \"d\"])\n",
    "        else:\n",
    "            print(\"BAD ONSET\")\n",
    "            \n",
    "        new_syll = random.choice(syll_dict[new_start])\n",
    "        elt[position] = new_syll\n",
    "        \n",
    "        to_return.append(elt)\n",
    "            \n",
    "            \n",
    "    return to_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unordered_short(overall_count):\n",
    "    count_1, count_2, count_3 = triple_summing_to(overall_count)\n",
    "    \n",
    "    to_modify = generate_training_set(count_1, count_2, count_3, 0, [])\n",
    "    \n",
    "    to_return = []\n",
    "    \n",
    "    end_change = random.choice([True, False])\n",
    "    \n",
    "    for elt in to_modify:\n",
    "        if len(elt) == 2 or len(elt) == 4:\n",
    "            position = 0\n",
    "        elif len(elt) == 6:\n",
    "            position = random.choice([0,1])\n",
    "        else:\n",
    "            print(\"BAD LENGTH\")\n",
    "            \n",
    "        if end_change:\n",
    "            elt = elt[::-1]\n",
    "            \n",
    "        to_replace = elt[position]\n",
    "        \n",
    "        if to_replace[0] == \"b\":\n",
    "            new_start = \"p\"\n",
    "        elif to_replace[0] == \"d\":\n",
    "            new_start = \"t\"\n",
    "        elif to_replace[0] == \"g\":\n",
    "            new_start = \"k\"\n",
    "        elif to_replace[0] == \"p\":\n",
    "            new_start = \"b\"\n",
    "        elif to_replace[0] == \"t\":\n",
    "            new_start = \"d\"\n",
    "        elif to_replace[0] == \"k\":\n",
    "            new_start = \"g\"\n",
    "        else:\n",
    "            print(\"BAD ONSET\")\n",
    "            \n",
    "        new_syll = random.choice(syll_dict[new_start])\n",
    "        elt[position] = new_syll\n",
    "        \n",
    "        if end_change:\n",
    "            elt = elt[::-1]\n",
    "        \n",
    "        to_return.append(elt)\n",
    "            \n",
    "            \n",
    "    return to_return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['de', 'ge', 'ko', 'di'],\n",
       " ['be', 'be'],\n",
       " ['de', 'de'],\n",
       " ['bi', 'di', 'de', 'tu', 'di', 'po'],\n",
       " ['de', 'bi', 'ge', 'ko', 'bi', 'tu']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_unordered_short(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_uniqe_subset(lst, count):\n",
    "    chosen_set = {}\n",
    "    chosen_lst = []\n",
    "    \n",
    "    for i in range(count):\n",
    "        satisfied = False\n",
    "        while not satisfied:\n",
    "            chosen = random.choice(lst)\n",
    "            if tuple(chosen) not in chosen_set:\n",
    "                satisfied = True\n",
    "        chosen_lst.append(chosen)\n",
    "        chosen_set[tuple(chosen)] = 1\n",
    "        \n",
    "    return chosen_lst\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_good = generate_test_good(count_test_good)\n",
    "test_set_nm = generate_nm_short(count_test_nm)\n",
    "test_set_longone = generate_nm_long(count_test_longone)\n",
    "test_set_nodep = generate_nodep_short(count_test_nodep)\n",
    "test_set_long_nodep = generate_nodep_long(count_test_long_nodep)\n",
    "test_set_long = generate_training_set(0,0,0,count_test_long, [])\n",
    "test_set_atob = generate_unordered_short(count_test_atob)\n",
    "training_set = generate_training_set(count_train_1, count_train_2, count_train_3, 0, test_set_good)\n",
    "test_set_seen = choose_uniqe_subset(training_set, count_test_seen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['y', 'good', 'di', 'bi', 'de', 'tu', 'po', 'to'],\n",
       " ['y', 'good', 'be', 'di', 'tu', 'po'],\n",
       " ['y', 'good', 'di', 'tu'],\n",
       " ['y', 'good', 'di', 'de', 'bi', 'po', 'to', 'tu'],\n",
       " ['y', 'good', 'gi', 'ko'],\n",
       " ['y', 'good', 'de', 'to'],\n",
       " ['y', 'good', 'gi', 'di', 'tu', 'ku'],\n",
       " ['y', 'good', 'be', 'bi', 'po', 'pu'],\n",
       " ['y', 'good', 'de', 'to'],\n",
       " ['y', 'good', 'gi', 'ko'],\n",
       " ['n', 'nm', 'bi', 'gi', 'ko'],\n",
       " ['n', 'nm', 'di', 'to', 'ko'],\n",
       " ['n', 'nm', 'de', 'gi', 'ku'],\n",
       " ['n', 'nm', 'di', 'to', 'po'],\n",
       " ['n', 'nm', 'gi', 'ku', 'to'],\n",
       " ['n', 'longone', 'bi', 'de', 'gi', 'ko', 'tu', 'po', 'to'],\n",
       " ['n', 'longone', 'gi', 'di', 'de', 'bi', 'pu', 'to', 'tu'],\n",
       " ['n', 'longone', 'di', 'gi', 'be', 'bi', 'po', 'pu', 'ko'],\n",
       " ['n', 'longone', 'di', 'gi', 'de', 'to', 'ko', 'tu', 'pu'],\n",
       " ['n', 'longone', 'gi', 'ge', 'de', 'di', 'tu', 'to', 'ko'],\n",
       " ['n', 'nodep', 'be', 'tu'],\n",
       " ['n', 'nodep', 'gi', 'de', 'gi', 'ku', 'to', 'po'],\n",
       " ['n', 'nodep', 'ge', 'gi', 'bi', 'pu', 'ku', 'tu'],\n",
       " ['n', 'nodep', 'bi', 'di', 'ge', 'ku', 'ko', 'po'],\n",
       " ['n', 'nodep', 'be', 'ko'],\n",
       " ['n', 'long_nodep', 'di', 'be', 'ge', 'de', 'to', 'pu', 'po', 'tu'],\n",
       " ['n', 'long_nodep', 'bi', 'be', 'ge', 'bi', 'po', 'ko', 'pu', 'tu'],\n",
       " ['n', 'long_nodep', 'be', 'di', 'de', 'de', 'tu', 'ko', 'to', 'pu'],\n",
       " ['n', 'long_nodep', 'ge', 'bi', 'de', 'di', 'tu', 'ku', 'po', 'ko'],\n",
       " ['n', 'long_nodep', 'gi', 'be', 'bi', 'ge', 'ko', 'po', 'pu', 'to'],\n",
       " ['y', 'long', 'di', 'be', 'gi', 'de', 'to', 'ku', 'pu', 'tu'],\n",
       " ['y', 'long', 'gi', 'di', 'de', 'ge', 'ku', 'tu', 'to', 'ko'],\n",
       " ['y', 'long', 'ge', 'di', 'bi', 'de', 'tu', 'pu', 'to', 'ku'],\n",
       " ['y', 'long', 'di', 'be', 'gi', 'de', 'tu', 'ko', 'po', 'to'],\n",
       " ['y', 'long', 'bi', 'di', 'de', 'gi', 'ku', 'to', 'tu', 'pu'],\n",
       " ['n', 'atob', 'pu', 'po'],\n",
       " ['n', 'atob', 'pu', 'be', 'po', 'pu'],\n",
       " ['n', 'atob', 'pu', 'po'],\n",
       " ['n', 'atob', 'tu', 'be', 'po', 'tu'],\n",
       " ['n', 'atob', 'po', 'bi', 'pu', 'po'],\n",
       " ['y', 'seen', 'ge', 'de', 'bi', 'pu', 'tu', 'ku'],\n",
       " ['y', 'seen', 'be', 'gi', 'ko', 'po'],\n",
       " ['y', 'seen', 'bi', 'po'],\n",
       " ['y', 'seen', 'de', 'tu'],\n",
       " ['y', 'seen', 'di', 'gi', 'ko', 'to'],\n",
       " ['y', 'seen', 'be', 'pu'],\n",
       " ['y', 'seen', 'ge', 'be', 'gi', 'ko', 'pu', 'ku'],\n",
       " ['y', 'seen', 'de', 'di', 'bi', 'pu', 'to', 'tu'],\n",
       " ['y', 'seen', 'ge', 'de', 'gi', 'ko', 'tu', 'ku'],\n",
       " ['y', 'seen', 'be', 'po']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = []\n",
    "\n",
    "for elt in test_set_good:\n",
    "    test_set.append([\"y\", \"good\"] + elt)\n",
    "    \n",
    "for elt in test_set_nm:\n",
    "    test_set.append([\"n\", \"nm\"] + elt)\n",
    "\n",
    "for elt in test_set_longone:\n",
    "    test_set.append([\"n\", \"longone\"] + elt)\n",
    "    \n",
    "for elt in test_set_nodep:\n",
    "    test_set.append([\"n\", \"nodep\"] + elt)\n",
    "    \n",
    "for elt in test_set_long_nodep:\n",
    "    test_set.append([\"n\", \"long_nodep\"] + elt)\n",
    "    \n",
    "for elt in test_set_long:\n",
    "    test_set.append([\"y\", \"long\"] + elt)\n",
    "    \n",
    "for elt in test_set_atob:\n",
    "    test_set.append([\"n\", \"atob\"] + elt)\n",
    "    \n",
    "for elt in test_set_seen:\n",
    "    test_set.append([\"y\", \"seen\"] + elt)\n",
    "\n",
    "test_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_list_of_lists(lol):\n",
    "    string = \"[\" + \", \".join(\"[\" + \", \".join(['\"' + y + '\"' for y in x]) + \"]\" for x in lol) + \"]\"\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"di\", \"gi\", \"ku\", \"to\"], [\"gi\", \"ku\"], [\"bi\", \"po\"], [\"be\", \"bi\", \"pu\", \"po\"], [\"di\", \"gi\", \"ko\", \"to\"], [\"gi\", \"ge\", \"ku\", \"ko\"], [\"be\", \"pu\"], [\"de\", \"bi\", \"gi\", \"ku\", \"po\", \"to\"], [\"gi\", \"bi\", \"de\", \"to\", \"po\", \"ku\"], [\"bi\", \"pu\"], [\"ge\", \"bi\", \"gi\", \"ko\", \"po\", \"ku\"], [\"be\", \"gi\", \"ko\", \"po\"], [\"be\", \"po\"], [\"di\", \"de\", \"be\", \"po\", \"tu\", \"to\"], [\"be\", \"po\"], [\"gi\", \"ge\", \"ko\", \"ku\"], [\"de\", \"tu\"], [\"be\", \"po\"], [\"bi\", \"di\", \"to\", \"pu\"], [\"de\", \"di\", \"to\", \"tu\"], [\"be\", \"ge\", \"ku\", \"pu\"], [\"ge\", \"de\", \"gi\", \"ko\", \"tu\", \"ku\"], [\"di\", \"de\", \"tu\", \"to\"], [\"de\", \"di\", \"bi\", \"pu\", \"to\", \"tu\"], [\"ge\", \"bi\", \"gi\", \"ko\", \"pu\", \"ku\"], [\"ge\", \"de\", \"bi\", \"pu\", \"tu\", \"ku\"], [\"gi\", \"bi\", \"ge\", \"ko\", \"pu\", \"ku\"], [\"be\", \"gi\", \"ku\", \"pu\"], [\"ge\", \"gi\", \"be\", \"po\", \"ko\", \"ku\"], [\"di\", \"to\"], [\"gi\", \"be\", \"pu\", \"ko\"], [\"de\", \"bi\", \"gi\", \"ku\", \"po\", \"tu\"], [\"de\", \"tu\"], [\"bi\", \"pu\"], [\"gi\", \"ku\"], [\"gi\", \"bi\", \"po\", \"ko\"], [\"ge\", \"gi\", \"ko\", \"ku\"], [\"ge\", \"be\", \"gi\", \"ko\", \"pu\", \"ku\"], [\"be\", \"ge\", \"gi\", \"ku\", \"ko\", \"po\"], [\"bi\", \"de\", \"di\", \"tu\", \"to\", \"pu\"], [\"di\", \"gi\", \"be\", \"po\", \"ko\", \"to\"], [\"de\", \"bi\", \"be\", \"po\", \"pu\", \"tu\"], [\"gi\", \"ku\"], [\"ge\", \"ko\"], [\"be\", \"po\"], [\"de\", \"bi\", \"po\", \"tu\"], [\"bi\", \"di\", \"tu\", \"pu\"], [\"be\", \"po\"]]\n"
     ]
    }
   ],
   "source": [
    "print(print_list_of_lists(training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of test items that are\n",
    "# the same as training items, for\n",
    "# each length\n",
    "#count_test_seen_1 = 10\n",
    "#count_test_seen_2 = 10\n",
    "#count_test_seen_3 = 10\n",
    "\n",
    "# Number of test items that are like the training\n",
    "# items but novel\n",
    "#count_test_good_1 = 10\n",
    "#count_test_good_2 = 10\n",
    "#count_test_good_3 = 10\n",
    "\n",
    "# Number of test items where the number of A's\n",
    "# and B's differs: either 2 A's and 3 B's, or \n",
    "# vice versa\n",
    "#count_test_nm_23 = 5\n",
    "#count_test_nm_32 = 5\n",
    "\n",
    "# Number of test items where the dependencies\n",
    "# are wrong, specified by the length and the\n",
    "# position where it is wrong.\n",
    "# E.g., length3_wrong2 means that n=3 and that\n",
    "# it is the 2nd position where the dependency is off\n",
    "#count_test_nodep_length1_wrong1 = 5\n",
    "#count_test_nodep_length2_wrong1 = 5\n",
    "#count_test_nodep_length3_wrong1 = 5\n",
    "#count_test_nodep_length3_wrong2 = 5\n",
    "\n",
    "# Number of test items that are long but\n",
    "# otherwise good\n",
    "#count_test_long = 5\n",
    "\n",
    "# Number of test items that are long and have an\n",
    "# unmatching number of A's and B's\n",
    "#count_test_longone_34 = 5\n",
    "#count_test_longone_43 = 5\n",
    "\n",
    "# Number of test items with n=4 and a dependency wrong\n",
    "# in position 1, 2, or 3\n",
    "#count_test_long_nodep_wrong1 = 5\n",
    "#count_test_long_nodep_wrong2 = 5\n",
    "#count_test_long_nodep_wrong3 = 5\n",
    "\n",
    "# Number of test items where an A or B has been changed\n",
    "#count_test_atob = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
